<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Filters and Frequencies Project</title>
    <style>
        body {
            margin: 50px;
        }
        /* Caption styling */
        .caption {
            font-size: 16px;
            color: #333;
            background-color: rgba(255, 255, 255, 0.8);
            padding: 8px;
            border-radius: 5px;
            text-align: center;
            margin-top: 5px;
            line-height: 1.5;
            display: inline-block;
            width: 100%;
        }

        /* Image container styling for example images */
        .image-container {
            position: relative;
            display: inline-block;
            text-align: center;
            margin-bottom: 20px;
        }

        .image-container img {
            width: 100%;
            display: block;
        }

        /* Add margin to the paragraph following the figure */
        p {
            margin-top: 20px;
        }

        /* Slider container */
        .slider-container {
            position: relative;
            width: 100%;
            margin: auto;
            overflow: hidden;
        }

        .slider-wrapper {
            width: 100%;
            overflow: hidden;
        }

        .slider {
            display: flex;
            transition: transform 0.5s ease-in-out;
        }

        .slide {
            min-width: 33.33%;
            box-sizing: border-box;
            padding: 10px;
            text-align: center;
        }

        .slide img {
            width: 100%;
        }

        /* Button for slider controls */
        button {
            position: absolute;
            top: 50%;
            transform: translateY(-50%);
            background-color: rgba(0, 0, 0, 0.5);
            color: white;
            border: none;
            padding: 10px;
            cursor: pointer;
            z-index: 10;
        }

        .prev {
            left: 10px;
        }

        .next {
            right: 10px;
        }

        button:hover {
            background-color: rgba(0, 0, 0, 0.8);
        }
    </style>
</head>
<body>
    <h1>Project 2: Fun with Filters and Frequencies</h1>

    <h2>Overview</h2>
    <p>This project consists of two parts: The first part consists of experiments with two different filtering approaches (Finite Difference Operator and Derivative of Gaussian Filter). The second part consists of a series of image transformation techniques through manipulating the frequencies of different images.</p>

    <h2>Part 1: Fun with Filters</h2>

    <h3>Part 1.1: Finite Difference Operator</h3>
    <p>In this section, we compute the partial derivatives in the <em>x</em> and <em>y</em> directions of the cameraman image using finite difference operators <em>D<sub>x</sub></em> and <em>D<sub>y</sub></em>, then apply convolution with these operators using <code>scipy.signal.convolve2d</code>. The gradient magnitude image is calculated by combining the partial derivatives. To obtain the result, we binarize the gradient magnitude image by selecting an appropriate threshold, which is chosen qualitatively to balance noise suppression while highlighting real edges.</p>

    <div class="image-container">
      <figure>
        <img src="../images/project2_images/result/part_1.1.jpg" style="width: 100%;">
      </figure>
    </div>

    <h3>Part 1.2: Derivative of Gaussian (DoG) Filter</h3>
    <p>The result from the previous section wasn't ideal. One way to improve this is to apply a Gaussian blur filter <em>G</em>. The image is first blurred by convolving it with a 2D Gaussian kernel to create a 1D Gaussian, and then using an outer product to produce the 2D version. After smoothing, we repeat the procedure of computing partial derivatives and the gradient magnitude. Here, instead of performing two separate convolutions, we create derivative of Gaussian (DoG) filters by convolving the Gaussian filter with <em>D<sub>x</sub></em> and <em>D<sub>y</sub></em>. The resulting DoG filters are then used to perform a single convolution for edge detection, producing results with smoother edges and less noise.</p>

    <div class="image-container">
      <figure>
        <img src="../images/project2_images/result/part_1.2.jpg" style="width: 100%;">
      </figure>
    </div>

    <h2>Part 2: Fun with Frequencies!</h2>

    <h3>Part 2.1: Image "Sharpening"</h3>
    <p>In this section, we use the unsharp masking technique to sharpen a blurry image. First, a Gaussian filter is applied to the image to produce a blurred version, which captures the low-frequency components. The high-frequency details are then obtained from subtracting the blurred image from the original. To enhance the sharpness, we add a scaled version of these high frequencies back to the original image. Although the image's resolution has not been improved, the sharpening effect nevertheless made the image look more "clear".</p>

    <div class="image-container">
      <figure>
        <img src="../images/project2_images/result/part_2.1.1_taj.jpg" style="width: 100%;">
      </figure>
    </div>

    <p>The fact that sharpening does not equate to increasing image resolution is evident in the second image - bars, which is blurry and only objects that were already clear to a certain extent like the cans inside have displayed noticeable improvements.</p>

    <div class="image-container">
      <figure>
        <img src="../images/project2_images/result/part_2.1.2_bars.jpg" style="width: 100%;">
      </figure>
    </div>

    <p>Furthermore, image resharpening can risk losing detail information. For the flower image below, which was already initially sharpened, appear to have bolder outlines. This effect gets increasingly apparent if we repeat the process a few more times as can be seen from the one below.</p>

    <div class="image-container">
      <figure>
        <img src="../images/project2_images/result/part_2.1.3_flower.jpg" style="width: 100%;">
      </figure>
    </div>

    <div class="image-container">
      <figure>
        <img src="../images/project2_images/result/part_2.1.4_flower_extra.jpg" style="width: 100%;">
      </figure>
    </div>

    <h3>Part 2.2: Hybrid Images</h3>
    <p>In this part, we create hybrid images that change their display based on the viewing distance (or how hard you squint), as described in the SIGGRAPH 2006 paper by Oliva, Torralba, and Schyns. Hybrid images are generated by blending the high-frequency content of one image with the low-frequency content of another. The high frequencies dominate when viewed up close, while only the low frequencies are perceived from a distance.</p>

    <p>The process involves first aligning two input images, which is critical for proper perception. After alignment, we apply a low-pass filter (a 2D Gaussian filter) to one image to extract its smooth, low frequency components. For the second image, we apply a high-pass filter by subtracting its Gaussian-filtered version from the original to extract the high frequency details. The two filtered images are combined to produce the hybrid image.</p>

    <div class="image-container">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/data/statue_1.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Statue 1</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/data/statue_2.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Statue 2</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/result/part_2.2.1_statue.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Hybrid Statue</figcaption>
        </div>
      </figure>
    </div>

    <div class="image-container" style="display: flex; justify-content: space-around; margin-bottom: 50px;">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/data/beach_1.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption style="margin: 5px 0 0;">Beach 1</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/data/beach_2.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption style="margin: 5px 0 0;">Beach 2</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/result/part_2.2.2_beach.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption style="margin: 5px 0 0;">Hybrid Beach</figcaption>
        </div>
      </figure>
    </div>

    <p>Below is the Fourier transform analysis conducted on the beach images to visualize the hybrid process. As we can see, after extracting the image's respective frequency, the plot appears more distinct in spectrum. This demonstrates the frequency distribution of the images and how they contribute to the hybrid effect.</p>

    <div class="image-container">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 0 10px; flex-basis: 40%; max-width: 40%;">
          <img src="../images/project2_images/result/part_2.2.3_ft_beach_1.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Beach 1 (unfiltered)</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 40%; max-width: 40%;">
          <img src="../images/project2_images/result/part_2.2.4_ft_beach_2.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Beach 2 (unfiltered)</figcaption>
        </div>
      </figure>
    </div>

    <div class="image-container">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 0 10px; flex-basis: 40%; max-width: 40%;">
          <img src="../images/project2_images/result/part_2.2.5_ft_low_freq_beach_1.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Beach 1 (low frequency)</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 40%; max-width: 40%;">
          <img src="../images/project2_images/result/part_2.2.6_ft_high_freq_beach_2.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Beach 2 (high frequency)</figcaption>
        </div>
      </figure>
    </div>

    <div class="image-container">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 0 10px; flex-basis: 60%; max-width: 60%;">
          <img src="../images/project2_images/result/part_2.2.7_ft_hybrid.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Hybrid Beach</figcaption>
        </div>
      </figure>
    </div>

    <h3>Part 2.3: Gaussian and Laplacian Stacks</h3>
    <p>In this section, we implement Gaussian and Laplacian stacks to prepare for multi-resolution blending. Unlike pyramids that downsample the image as we traverse, the stacks here maintain the same image dimension at each level. The Gaussian stack applies the Gaussian filter at each level. The Laplacian stack is constructed by computing the difference between successive levels of the Gaussian stack, capturing the high-frequency details at each level. Both stacks are stored in a 3D matrix (for grayscale images) where each level corresponds to a different degree of smoothing or high-frequency detail extraction. These stacks allow us to blend images in the next section of the project.</p>

    <p>The first row displays the gaussian stacks, and the second row displays the laplacian stacks, both from level 0 to 4.</p>

    <div class="image-container">
      <figure style="width: 100%;">
        <div style="text-align: center; padding: 0px; width: 100%;">
          <img src="../images/project2_images/result/part_2.3.1_apple.jpg" style="width: 100%; height: 100%; object-fit: contain;">
        </div>
        <div style="text-align: center; padding: 0px; width: 100%;">
          <img src="../images/project2_images/result/part_2.3.2_orange.jpg" style="width: 100%; height: 100%; object-fit: contain;">
        </div>
      </figure>
    </div>

    <h3>Part 2.4: Multiresolution Blending</h3>
    <p>Here, we utilize results from the previous section to implement multiresolution blending. This approach follows the ideas presented in Burt and Adelson’s 1983 paper. To blend two images, we first create Gaussian and Laplacian stacks for both input images (e.g., the apple and orange) and for the blending mask. Using the stacks, we blend the images by combining their Laplacian levels, guided by the Gaussian-blurred mask at each level. This results in a seamless blend where the transition between the two images is smooth and natural (though a part of the natural transition requires the two images being a plausible combination). After creating the blended Laplacian stack, we reconstruct the final blended image by adding the levels back together, starting from the highest to the lowest.</p>

    <div class="image-container">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/data/apple.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Apple</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/data/orange.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Orange</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/result/part_2.4.1_oraple_mask.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Mask</figcaption>
        </div>
      </figure>
    </div>

    <div class="image-container">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 10px 0; flex-basis: 60%; max-width: 60%;">
          <img src="../images/project2_images/result/part_2.4.2_oraple.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Oraple</figcaption>
        </div>
      </figure>
    </div>

    <div class="image-container">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/data/fo.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Image 1</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/data/mo.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Image 2</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/result/part_2.4.3_fomo_mask.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Mask</figcaption>
        </div>
      </figure>
    </div>

    <div class="image-container">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 10px 0; flex-basis: 40%; max-width: 40%;">
          <img src="../images/project2_images/result/part_2.4.4_fomo.jpg" style="width: 100%; height: 100%; object-fit: contain;">
        </div>
      </figure>
    </div>

    <p>Blending using irregular masks is more difficult but similar in essence. For the result below, I used an external tool to crop out the image I want to blend and convert it to pure binary (i.e., mask).</p>

    <div class="image-container">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/data/cat.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Cat</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/data/box.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Box</figcaption>
        </div>
        <div style="text-align: center; padding: 0 10px; flex-basis: 33.33%; max-width: 33.33%;">
          <img src="../images/project2_images/result/part_2.4.5_cat_mask.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Mask</figcaption>
        </div>
      </figure>
    </div>

    <div class="image-container">
      <figure style="display: flex; justify-content: space-around; align-items: center; width: 100%;">
        <div style="text-align: center; padding: 10px 0; flex-basis: 60%; max-width: 60%;">
          <img src="../images/project2_images/result/part_2.4.6_cat_drumstick.jpg" style="width: 100%; height: 100%; object-fit: contain;">
          <figcaption>Cat drumstick</figcaption>
        </div>
      </figure>
    </div>

    <p>Overall, a key takeaway is the role of Gaussian blur and frequency in image processing (especially blending). By applying Gaussian filters, we can effectively highlight the key components of an image, which can then help us extract the information for edge detection. Furthermore, we can effectively smooth images, extract high-frequency edges, and create seamless transitions between images in tasks like hybrid image creation and multiresolution blending. It is through this project that I better understand the essence of image in digital representation – that they are just numbers, as Prof. Efros mentioned in the introductory lecture. During the process of work, a significant amount of time was allocated to adjusting the parameters (e.g., channels, resolution, dimension, frequency, kernel, standard deviation (of Gaussian), etc.), as a change to any of them may cause the whole pipeline to produce a completely different result.</p>
</body>
</html>
